{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n\nThe goal of this competition is to **detect freezing of gait (FOG)**, a debilitating symptom that afflicts many people **with Parkinson’s disease**. It is requred to **develop a machine learning model trained on data collected from a wearable 3D lower back sensor** to better understand **when and why FOG episodes occur**.","metadata":{"papermill":{"duration":0.026599,"end_time":"2023-05-14T06:28:35.319714","exception":false,"start_time":"2023-05-14T06:28:35.293115","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Import Libraries","metadata":{"papermill":{"duration":0.024773,"end_time":"2023-05-14T06:28:35.368114","exception":false,"start_time":"2023-05-14T06:28:35.343341","status":"completed"},"tags":[]}},{"cell_type":"code","source":"!pip install tsflex\n!pip install alive-progress","metadata":{"execution":{"iopub.status.busy":"2023-05-25T20:13:01.831020Z","iopub.execute_input":"2023-05-25T20:13:01.832211Z","iopub.status.idle":"2023-05-25T20:13:28.403102Z","shell.execute_reply.started":"2023-05-25T20:13:01.832162Z","shell.execute_reply":"2023-05-25T20:13:28.401884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from alive_progress import alive_bar\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom imblearn.over_sampling import SMOTE\nimport scipy.stats as ss\nfrom tsflex.features import MultipleFeatureDescriptors, FeatureCollection, FeatureDescriptor\nfrom tsflex.features.utils import make_robust\nimport warnings\n","metadata":{"papermill":{"duration":1.340262,"end_time":"2023-05-14T06:28:36.731675","exception":false,"start_time":"2023-05-14T06:28:35.391413","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T20:13:28.406314Z","iopub.execute_input":"2023-05-25T20:13:28.406815Z","iopub.status.idle":"2023-05-25T20:13:29.948158Z","shell.execute_reply.started":"2023-05-25T20:13:28.406762Z","shell.execute_reply":"2023-05-25T20:13:29.947089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In addition, **tdcsfog_metadata.csv identifies** each series in the tdcsfog dataset by **a unique Subject, Visit, Test, and Medication condition**.","metadata":{"papermill":{"duration":0.024886,"end_time":"2023-05-14T06:28:37.543932","exception":false,"start_time":"2023-05-14T06:28:37.519046","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# tdcsfog metadata file\ntdcsfog_metadata = pd.read_csv(\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/defog_metadata.csv\")\ntdcsfog_metadata.head(5)","metadata":{"papermill":{"duration":0.050176,"end_time":"2023-05-14T06:28:37.619958","exception":false,"start_time":"2023-05-14T06:28:37.569782","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T20:13:29.953550Z","iopub.execute_input":"2023-05-25T20:13:29.953857Z","iopub.status.idle":"2023-05-25T20:13:30.001988Z","shell.execute_reply.started":"2023-05-25T20:13:29.953829Z","shell.execute_reply":"2023-05-25T20:13:30.001219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Take All the CSV Files in the Train tdcsfog Folder","metadata":{"papermill":{"duration":0.02634,"end_time":"2023-05-14T06:28:38.924186","exception":false,"start_time":"2023-05-14T06:28:38.897846","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def slope(x): return (x[-1] - x[0]) / x[0] if x[0] else 0\ndef abs_diff_mean(x): return np.mean(np.abs(x[1:] - x[:-1])) if len(x) > 1 else 0\ndef diff_std(x): return np.std(x[1:] - x[:-1]) if len(x) > 1 else 0\n\nstrides = [5] # If stride size == window size there is no overlap between windows\nwindows = [50]\n\n\nfuncs = [make_robust(f) for f in [np.min,np.var, np.max, np.std, np.mean, slope, ss.skew, ss.kurtosis, abs_diff_mean, diff_std, np.sum,]]\n\nfc = FeatureCollection(\n    MultipleFeatureDescriptors(\n          functions=funcs,\n          series_names=[\"AccV\", \"AccML\", \"AccAP\"],\n          windows=windows,\n          strides=strides[0],\n    )\n)\n\nnpmean = make_robust(np.mean)\n\nfc.add(FeatureDescriptor(npmean, \"StartHesitation\", windows[0], strides[0]))\nfc.add(FeatureDescriptor(npmean, \"Walking\", windows[0], strides[0]))\nfc.add(FeatureDescriptor(npmean, \"Turn\", windows[0], strides[0]))","metadata":{"papermill":{"duration":18.008288,"end_time":"2023-05-14T06:28:56.959744","exception":false,"start_time":"2023-05-14T06:28:38.951456","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T20:13:30.003329Z","iopub.execute_input":"2023-05-25T20:13:30.003881Z","iopub.status.idle":"2023-05-25T20:13:30.014619Z","shell.execute_reply.started":"2023-05-25T20:13:30.003846Z","shell.execute_reply":"2023-05-25T20:13:30.013418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the directory path to the folder containing the CSV files.\ntdcsfog_path = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/tdcsfog'\n\n# Initialize an empty list to store the dataframes.\ntdcsfog_list = []\n\n\n# Loop through each file in the directory and read it into a dataframe.\nfor file_name in os.listdir(tdcsfog_path):\n    if file_name.endswith('.csv'):\n        file_path = os.path.join(tdcsfog_path, file_name)\n        file = pd.read_csv(file_path)\n        file.Time = file.Time # / (len(file) - 1)\n        tdcsfog_list.append(file)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T20:13:30.016596Z","iopub.execute_input":"2023-05-25T20:13:30.017297Z","iopub.status.idle":"2023-05-25T20:13:46.712120Z","shell.execute_reply.started":"2023-05-25T20:13:30.017238Z","shell.execute_reply":"2023-05-25T20:13:46.711313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For each tdcsfog DataFrame, extract the features and add them to the total Dataframe.\n\n# Initialize final dataframe\ntdcsfog_final = pd.DataFrame()\n\nfor idx, tdcsfog in enumerate(tdcsfog_list): \n    tdcsfog = tdcsfog.reset_index(drop = True)\n    if idx % int(len(tdcsfog_list)/10) == 0 and idx != 0:\n        print(\"Progress: \" + str(int(idx/int(len(tdcsfog_list)/10)) * 10) + \"%\")\n    df_feats = fc.calculate(data=[tdcsfog], window_idx=\"end\", approve_sparsity=True, return_df=True)\n    df_feats = df_feats.join(tdcsfog.drop(columns = [\"StartHesitation\",\"Turn\",\"Walking\"]))\n    tdcsfog_final = pd.concat([tdcsfog_final,df_feats],ignore_index = True)\n    \nprint(tdcsfog_final.tail())","metadata":{"execution":{"iopub.status.busy":"2023-05-25T20:39:17.657519Z","iopub.execute_input":"2023-05-25T20:39:17.657874Z","iopub.status.idle":"2023-05-25T20:39:23.168182Z","shell.execute_reply.started":"2023-05-25T20:39:17.657836Z","shell.execute_reply":"2023-05-25T20:39:23.167159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It is better to reduce the memory usage. Reference: [Reducing DataFrame memory size by ~65%](https://www.kaggle.com/code/arjanso/reducing-dataframe-memory-size-by-65)","metadata":{"papermill":{"duration":0.027012,"end_time":"2023-05-14T06:28:57.01431","exception":false,"start_time":"2023-05-14T06:28:56.987298","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def reduce_memory_usage(df):\n    \n    start_mem = df.memory_usage().sum() / 1024 ** 2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype.name\n        if ((col_type != 'datetime64[ns]') & (col_type != 'category')):\n            if (col_type != 'object'):\n                c_min = df[col].min()\n                c_max = df[col].max()\n\n                if str(col_type)[:3] == 'int':\n                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                        df[col] = df[col].astype(np.int8)\n                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                        df[col] = df[col].astype(np.int16)\n                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                        df[col] = df[col].astype(np.int32)\n                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                        df[col] = df[col].astype(np.int64)\n\n                else:\n                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                        df[col] = df[col].astype(np.float16)\n                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                        df[col] = df[col].astype(np.float32)\n                    else:\n                        pass\n            else:\n                df[col] = df[col].astype('category')\n    mem_usg = df.memory_usage().sum() / 1024 ** 2 \n    print(\"Memory usage became: \",mem_usg,\" MB\")\n    \n    return df","metadata":{"papermill":{"duration":0.050491,"end_time":"2023-05-14T06:28:57.092322","exception":false,"start_time":"2023-05-14T06:28:57.041831","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T20:13:51.049357Z","iopub.execute_input":"2023-05-25T20:13:51.049778Z","iopub.status.idle":"2023-05-25T20:13:51.068687Z","shell.execute_reply.started":"2023-05-25T20:13:51.049740Z","shell.execute_reply":"2023-05-25T20:13:51.066375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tdcsfog = reduce_memory_usage(tdcsfog_final)","metadata":{"papermill":{"duration":0.635449,"end_time":"2023-05-14T06:28:57.755209","exception":false,"start_time":"2023-05-14T06:28:57.11976","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T20:13:51.069995Z","iopub.execute_input":"2023-05-25T20:13:51.070517Z","iopub.status.idle":"2023-05-25T20:13:51.125972Z","shell.execute_reply.started":"2023-05-25T20:13:51.070486Z","shell.execute_reply":"2023-05-25T20:13:51.124777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tdcsfog.describe()","metadata":{"papermill":{"duration":3.461726,"end_time":"2023-05-14T06:29:01.244355","exception":false,"start_time":"2023-05-14T06:28:57.782629","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T20:13:51.130344Z","iopub.execute_input":"2023-05-25T20:13:51.130721Z","iopub.status.idle":"2023-05-25T20:13:51.283156Z","shell.execute_reply.started":"2023-05-25T20:13:51.130690Z","shell.execute_reply":"2023-05-25T20:13:51.282051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tdcsfog['StartHesitation__mean__w=' + str(windows[0])].mean()","metadata":{"papermill":{"duration":0.047747,"end_time":"2023-05-14T06:29:01.319722","exception":false,"start_time":"2023-05-14T06:29:01.271975","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T20:13:51.284569Z","iopub.execute_input":"2023-05-25T20:13:51.285466Z","iopub.status.idle":"2023-05-25T20:13:51.293445Z","shell.execute_reply.started":"2023-05-25T20:13:51.285424Z","shell.execute_reply":"2023-05-25T20:13:51.292314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tdcsfog['Turn__mean__w='+ str(windows[0])].mean()","metadata":{"papermill":{"duration":0.046553,"end_time":"2023-05-14T06:29:01.394608","exception":false,"start_time":"2023-05-14T06:29:01.348055","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T20:13:51.294756Z","iopub.execute_input":"2023-05-25T20:13:51.295619Z","iopub.status.idle":"2023-05-25T20:13:51.304511Z","shell.execute_reply.started":"2023-05-25T20:13:51.295581Z","shell.execute_reply":"2023-05-25T20:13:51.303318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tdcsfog['Walking__mean__w='+str(windows[0])].mean()","metadata":{"papermill":{"duration":0.046692,"end_time":"2023-05-14T06:29:01.469117","exception":false,"start_time":"2023-05-14T06:29:01.422425","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T20:13:51.306334Z","iopub.execute_input":"2023-05-25T20:13:51.307175Z","iopub.status.idle":"2023-05-25T20:13:51.318487Z","shell.execute_reply.started":"2023-05-25T20:13:51.307137Z","shell.execute_reply":"2023-05-25T20:13:51.317337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(tdcsfog)","metadata":{"papermill":{"duration":0.039717,"end_time":"2023-05-14T06:29:01.536756","exception":false,"start_time":"2023-05-14T06:29:01.497039","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T20:13:51.319839Z","iopub.execute_input":"2023-05-25T20:13:51.320252Z","iopub.status.idle":"2023-05-25T20:13:51.331507Z","shell.execute_reply.started":"2023-05-25T20:13:51.320215Z","shell.execute_reply":"2023-05-25T20:13:51.330337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Take All the CSV Files in the Train defog Folder","metadata":{"papermill":{"duration":0.033964,"end_time":"2023-05-14T06:33:55.834755","exception":false,"start_time":"2023-05-14T06:33:55.800791","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Set the directory path to the folder containing the CSV files.\ndefog_path = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/defog'\n\n# Initialize an empty list to store the dataframes.\ndefog_list = []\n\n# Loop through each file in the directory and read it into a dataframe.\nfor file_name in os.listdir(defog_path):\n    if file_name.endswith('.csv'):\n        file_path = os.path.join(defog_path, file_name)\n        file = pd.read_csv(file_path)\n        file.Time = file.Time # / (len(file) - 1)\n        file = file[(file['Task'] == 1) & (file['Valid'] == 1)]\n        defog_list.append(file)\n","metadata":{"papermill":{"duration":24.575548,"end_time":"2023-05-14T06:34:20.444682","exception":false,"start_time":"2023-05-14T06:33:55.869134","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T20:13:51.333669Z","iopub.execute_input":"2023-05-25T20:13:51.334097Z","iopub.status.idle":"2023-05-25T20:14:13.722535Z","shell.execute_reply.started":"2023-05-25T20:13:51.334057Z","shell.execute_reply":"2023-05-25T20:14:13.721673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For each defog DataFrame, extract the features and add them to the total Dataframe.\n# Initialize final dataframe\ndefog_final = pd.DataFrame()\n\nfor idx, defog in enumerate(defog_list): \n    defog = defog.reset_index(drop = True)\n    if idx % int(len(defog_list)/10) == 0 and idx != 0:\n        print(\"Progress: \" + str(int(idx/int(len(defog_list)/10)) * 10) + \"%\")\n    df_feats = fc.calculate(data=[defog], window_idx=\"end\", approve_sparsity=True, return_df=True)\n    df_feats = df_feats.join(defog.drop(columns = [\"StartHesitation\",\"Turn\",\"Walking\", \"Task\", \"Valid\"]))\n    defog_final = pd.concat([defog_final,df_feats],ignore_index = True)\n    \nprint(defog_final.tail())","metadata":{"execution":{"iopub.status.busy":"2023-05-25T20:36:49.825995Z","iopub.execute_input":"2023-05-25T20:36:49.826547Z","iopub.status.idle":"2023-05-25T20:37:05.714000Z","shell.execute_reply.started":"2023-05-25T20:36:49.826496Z","shell.execute_reply":"2023-05-25T20:37:05.712669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"defog = reduce_memory_usage(defog_final)","metadata":{"papermill":{"duration":1.350518,"end_time":"2023-05-14T06:34:21.831438","exception":false,"start_time":"2023-05-14T06:34:20.48092","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T20:37:13.904046Z","iopub.execute_input":"2023-05-25T20:37:13.904714Z","iopub.status.idle":"2023-05-25T20:37:13.986964Z","shell.execute_reply.started":"2023-05-25T20:37:13.904672Z","shell.execute_reply":"2023-05-25T20:37:13.985487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We are going to use valid data only.**","metadata":{"papermill":{"duration":0.034693,"end_time":"2023-05-14T06:34:21.90116","exception":false,"start_time":"2023-05-14T06:34:21.866467","status":"completed"},"tags":[]}},{"cell_type":"code","source":"defog.describe()","metadata":{"papermill":{"duration":1.969354,"end_time":"2023-05-14T06:34:24.573134","exception":false,"start_time":"2023-05-14T06:34:22.60378","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T20:37:17.806628Z","iopub.execute_input":"2023-05-25T20:37:17.807017Z","iopub.status.idle":"2023-05-25T20:37:18.087653Z","shell.execute_reply.started":"2023-05-25T20:37:17.806987Z","shell.execute_reply":"2023-05-25T20:37:18.086560Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We merge tdcsfog and defog datasets into one merged dataset.**","metadata":{"papermill":{"duration":0.035153,"end_time":"2023-05-14T06:34:24.643669","exception":false,"start_time":"2023-05-14T06:34:24.608516","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Concatenate the dataframes vertically using pd.concat().\nmerged = pd.concat([tdcsfog, defog], axis = 0, ignore_index = True)\n\nmerged","metadata":{"papermill":{"duration":0.139524,"end_time":"2023-05-14T06:34:24.818653","exception":false,"start_time":"2023-05-14T06:34:24.679129","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T20:38:08.353820Z","iopub.execute_input":"2023-05-25T20:38:08.354223Z","iopub.status.idle":"2023-05-25T20:38:08.419234Z","shell.execute_reply.started":"2023-05-25T20:38:08.354192Z","shell.execute_reply":"2023-05-25T20:38:08.418151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Dataset\n\nFirst, we need to **split the data into input features (i.e. \"Time\", \"AccV\", \"AccML\", and \"AccAP\") and target variables (i.e. \"StartHesitation\", \"Turn\", and \"Walking\")**. We can do this using the .iloc method to select the appropriate columns.","metadata":{"papermill":{"duration":0.036051,"end_time":"2023-05-14T06:34:24.891554","exception":false,"start_time":"2023-05-14T06:34:24.855503","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# input features\n# merged['label'] = np.where(merged['Turn'] == 1, 1,\n#                      np.where(merged['Walking'] == 1, 2,\n#                      np.where(merged['StartHesitation'] == 1, 3, 0)))\n\n# Use smote to create synthetic data\n\n# smote = SMOTE(random_state = 4, k_neighbors=100)\n# X_syn, y_syn = smote.fit_resample(X_merged, merged['label'])","metadata":{"papermill":{"duration":0.208778,"end_time":"2023-05-14T06:34:25.136244","exception":false,"start_time":"2023-05-14T06:34:24.927466","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T20:14:32.544673Z","iopub.execute_input":"2023-05-25T20:14:32.545685Z","iopub.status.idle":"2023-05-25T20:14:32.551376Z","shell.execute_reply.started":"2023-05-25T20:14:32.545643Z","shell.execute_reply":"2023-05-25T20:14:32.550340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create Synthetic dataset\n# syn = pd.concat([X_syn,y_syn.to_frame(name = \"label\")], axis=1)\n# syn[\"Turn\"], syn[\"Walking\"], syn[\"StartHesitation\"] = (syn[\"label\"] == 1).astype(int), (syn[\"label\"] == 2).astype(int), (syn[\"label\"] == 3).astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T20:14:32.553138Z","iopub.execute_input":"2023-05-25T20:14:32.553919Z","iopub.status.idle":"2023-05-25T20:14:32.560258Z","shell.execute_reply.started":"2023-05-25T20:14:32.553880Z","shell.execute_reply":"2023-05-25T20:14:32.559094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tot = pd.concat([merged,syn])\n# tot = tot.sort_values(\"Time\",ignore_index = True)\n\n# Normalize time\n# tot[\"Time\"] = tot[\"Time\"] / (len(tot) - 1)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T20:14:32.561846Z","iopub.execute_input":"2023-05-25T20:14:32.562365Z","iopub.status.idle":"2023-05-25T20:14:32.574560Z","shell.execute_reply.started":"2023-05-25T20:14:32.562325Z","shell.execute_reply":"2023-05-25T20:14:32.573570Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tot = reduce_memory_usage(tot)\ntot = reduce_memory_usage(merged)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T20:14:32.575719Z","iopub.execute_input":"2023-05-25T20:14:32.576070Z","iopub.status.idle":"2023-05-25T20:14:32.764631Z","shell.execute_reply.started":"2023-05-25T20:14:32.576040Z","shell.execute_reply":"2023-05-25T20:14:32.763506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = np.array([tot['Walking__mean__w='+ str(windows[0])], tot['StartHesitation__mean__w=' + str(windows[0])], tot['Turn__mean__w='+ str(windows[0])]])\n\nlabels = np.argmax(data, axis = 0)\nsums = np.sum(data, axis = 0)\nlabels = np.where(sums == 0 , 5, labels)\n\n\ntot['Walking'] = np.where(labels == 0 , 1, 0)\ntot['StartHesitation'] = np.where(labels == 1 , 1, 0)\ntot['Turn'] = np.where(labels == 2 , 1, 0)\n\n# try:\n#     tot = tot.drop(columns=[\"Time\"])\n# finally:\n#     pass\n\n# Change this by hand if you want to try more features\nX_tot = pd.concat([tot.iloc[:, 0:33],tot.iloc[:, 36:39]], axis = 1, ignore_index = False) \n\ny1 = tot['StartHesitation']  # target variable for StartHesitation\ny2 = tot['Turn']  # target variable for Turn\ny3 = tot['Walking']  # target variable for Walking\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T20:18:21.431306Z","iopub.execute_input":"2023-05-25T20:18:21.431789Z","iopub.status.idle":"2023-05-25T20:18:21.534783Z","shell.execute_reply.started":"2023-05-25T20:18:21.431752Z","shell.execute_reply":"2023-05-25T20:18:21.533307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most of the target variables are 0. We had better **create each balanced dataset with the target variables of 0 and 1 equally**.","metadata":{"papermill":{"duration":0.035961,"end_time":"2023-05-14T06:34:25.208958","exception":false,"start_time":"2023-05-14T06:34:25.172997","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Find the positions of y1 where it equals 0.\ny1_zeros = np.where(y1 == 0)[0]\ny1_ones = np.where(y1 == 1)[0]\n\n# Choose the same number of samples with y1 == 1 as there are with y1 == 0.\nnum1_ones = (y1 == 1).sum()\nnp.random.seed(42)\ny1_zeros = np.random.choice(np.where(y1 == 0)[0], size = num1_ones, replace = False)\n\n# Combine the positions of y1 == 0 and y1 == 1.\ny1_balanced_idxs = np.sort(np.concatenate([y1_zeros, y1_ones]))\n\n# Use the balanced indices to get the corresponding rows of X and y1.\nX1_balanced = X_tot.iloc[y1_balanced_idxs, :]\ny1_balanced = y1.iloc[y1_balanced_idxs]","metadata":{"papermill":{"duration":0.760961,"end_time":"2023-05-14T06:34:26.007999","exception":false,"start_time":"2023-05-14T06:34:25.247038","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T17:09:40.776352Z","iopub.status.idle":"2023-05-25T17:09:40.776683Z","shell.execute_reply.started":"2023-05-25T17:09:40.776517Z","shell.execute_reply":"2023-05-25T17:09:40.776532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find the positions of y2 where it equals 0.\ny2_zeros = np.where(y2 == 0)[0]\ny2_ones = np.where(y2 == 1)[0]\n\n# Choose the same number of samples with y2 == 1 as there are with y2 == 0.\nnum2_ones = (y2 == 1).sum()\nnp.random.seed(42)\ny2_zeros = np.random.choice(np.where(y2 == 0)[0], size = num2_ones, replace = False)\n\n# Combine the positions of y2 == 0 and y2 == 1.\ny2_balanced_idxs = np.sort(np.concatenate([y2_zeros, y2_ones]))\n\n# Use the balanced indices to get the corresponding rows of X and y1.\nX2_balanced = X_tot.iloc[y2_balanced_idxs, :]\ny2_balanced = y2.iloc[y2_balanced_idxs]","metadata":{"papermill":{"duration":1.218739,"end_time":"2023-05-14T06:34:27.263905","exception":false,"start_time":"2023-05-14T06:34:26.045166","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T17:09:40.777597Z","iopub.status.idle":"2023-05-25T17:09:40.777939Z","shell.execute_reply.started":"2023-05-25T17:09:40.777758Z","shell.execute_reply":"2023-05-25T17:09:40.777773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find the positions of y3 where it equals 0.\ny3_zeros = np.where(y3 == 0)[0]\ny3_ones = np.where(y3 == 1)[0]\n\n# Choose the same number of samples with y3 == 1 as there are with y3 == 0.\nnum3_ones = (y3 == 1).sum()\nnp.random.seed(42)\ny3_zeros = np.random.choice(np.where(y3 == 0)[0], size = num3_ones, replace = False)\n\n# Combine the positions of y3 == 0 and y3 == 1.\ny3_balanced_idxs = np.sort(np.concatenate([y3_zeros, y3_ones]))\n\n# Use the balanced indices to get the corresponding rows of X and y3.\nX3_balanced = X_tot.iloc[y3_balanced_idxs, :]\ny3_balanced = y3.iloc[y3_balanced_idxs]","metadata":{"papermill":{"duration":0.801883,"end_time":"2023-05-14T06:34:28.102399","exception":false,"start_time":"2023-05-14T06:34:27.300516","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T17:09:40.779237Z","iopub.status.idle":"2023-05-25T17:09:40.779561Z","shell.execute_reply.started":"2023-05-25T17:09:40.779397Z","shell.execute_reply":"2023-05-25T17:09:40.779412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, we can **split the data into training and testing sets using the train_test_split function from scikit-learn**.","metadata":{"papermill":{"duration":0.036394,"end_time":"2023-05-14T06:34:28.17924","exception":false,"start_time":"2023-05-14T06:34:28.142846","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX1_train, X1_test, y1_train, y1_test = train_test_split(X1_balanced, y1_balanced, test_size = 0.2, random_state = 42)\nX2_train, X2_test, y2_train, y2_test = train_test_split(X2_balanced, y2_balanced, test_size = 0.2, random_state = 42)\nX3_train, X3_test, y3_train, y3_test = train_test_split(X3_balanced, y3_balanced, test_size = 0.2, random_state = 42)","metadata":{"papermill":{"duration":1.062844,"end_time":"2023-05-14T06:34:29.279157","exception":false,"start_time":"2023-05-14T06:34:28.216313","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T17:09:40.780640Z","iopub.status.idle":"2023-05-25T17:09:40.780978Z","shell.execute_reply.started":"2023-05-25T17:09:40.780800Z","shell.execute_reply":"2023-05-25T17:09:40.780815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then, we **standardize the independent variables**.","metadata":{"papermill":{"duration":0.035687,"end_time":"2023-05-14T06:34:29.350635","exception":false,"start_time":"2023-05-14T06:34:29.314948","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# Standardize the independent variables.\nscaler1 = StandardScaler()\nX1_train = scaler1.fit_transform(X1_train)\nX1_test = scaler1.transform(X1_test)\n\nscaler2 = StandardScaler()\nX2_train = scaler2.fit_transform(X2_train)\nX2_test = scaler2.transform(X2_test)\n\nscaler3 = StandardScaler()\nX3_train = scaler3.fit_transform(X3_train)\nX3_test = scaler3.transform(X3_test)","metadata":{"papermill":{"duration":0.910372,"end_time":"2023-05-14T06:34:30.297294","exception":false,"start_time":"2023-05-14T06:34:29.386922","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create, Train, and Evaluate Model\n\nFinally, we can **create and train three separate models**, one for each target variable, using a suitable algorithm.\n       \n### This time we use **Random Forest Regressor instead of the Logistic Regression model**.\n\n**For a Logistic Regression model, please see [PD FOG Prediction Baseline by Logistic Regression](https://www.kaggle.com/code/gokifujiya/pd-fog-prediction-baseline-by-logistic-regression).**","metadata":{"papermill":{"duration":0.035684,"end_time":"2023-05-14T06:34:30.369288","exception":false,"start_time":"2023-05-14T06:34:30.333604","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#from sklearn.linear_model import LogisticRegression\nfrom sklearn import ensemble\n\n# Create three separate logistic regression models.\n#model1 = LogisticRegression()\n#model2 = LogisticRegression()\n#model3 = LogisticRegression()\n\n# Create three separate Random Forest Regressor models.\nmodel1 = ensemble.RandomForestRegressor(n_estimators = 100, max_depth = 7, n_jobs = -1, random_state = 42)\nmodel2 = ensemble.RandomForestRegressor(n_estimators = 100, max_depth = 7, n_jobs = -1, random_state = 42)\nmodel3 = ensemble.RandomForestRegressor(n_estimators = 100, max_depth = 7, n_jobs = -1, random_state = 42)\n\n# Train the models on the training data.\nmodel1.fit(X1_train, y1_train)\nmodel2.fit(X2_train, y2_train)\nmodel3.fit(X3_train, y3_train)\n\n# Evaluate the models on the test data.\nprint('R2 for StartHesitation:', model1.score(X1_test, y1_test))\nprint('R2 for Turn:', model2.score(X2_test, y2_test))\nprint('R2 for Walking:', model3.score(X3_test, y3_test))","metadata":{"papermill":{"duration":390.611171,"end_time":"2023-05-14T06:41:01.016047","exception":false,"start_time":"2023-05-14T06:34:30.404876","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-22T10:42:44.367241Z","iopub.execute_input":"2023-05-22T10:42:44.368482Z","iopub.status.idle":"2023-05-22T11:02:21.807463Z","shell.execute_reply.started":"2023-05-22T10:42:44.368433Z","shell.execute_reply":"2023-05-22T11:02:21.805568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Recreate Dataset and Training\n\n**For submission we should not split the datasets to keep the amount of data and to get a higher score.**","metadata":{"papermill":{"duration":0.035718,"end_time":"2023-05-14T06:41:01.088534","exception":false,"start_time":"2023-05-14T06:41:01.052816","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# Standardize the independent variables.\nscaler1 = StandardScaler()\nX1_balanced = scaler1.fit_transform(X1_balanced)\n\nscaler2 = StandardScaler()\nX2_balanced = scaler2.fit_transform(X2_balanced)\n\nscaler3 = StandardScaler()\nX3_balanced = scaler3.fit_transform(X3_balanced)","metadata":{"papermill":{"duration":0.995912,"end_time":"2023-05-14T06:41:02.120305","exception":false,"start_time":"2023-05-14T06:41:01.124393","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-14T07:33:13.302169Z","iopub.execute_input":"2023-05-14T07:33:13.302939Z","iopub.status.idle":"2023-05-14T07:33:14.567493Z","shell.execute_reply.started":"2023-05-14T07:33:13.302907Z","shell.execute_reply":"2023-05-14T07:33:14.566357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from sklearn.linear_model import LogisticRegression\nfrom sklearn import ensemble\n\n# Create three separate logistic regression models.\n#model1 = LogisticRegression()\n#model2 = LogisticRegression()\n#model3 = LogisticRegression()\n\n# Create three separate Random Forest Regressor models.\nmodel1 = ensemble.RandomForestRegressor(n_estimators = 100, max_depth = 7, n_jobs = -1, random_state = 42)\nmodel2 = ensemble.RandomForestRegressor(n_estimators = 100, max_depth = 7, n_jobs = -1, random_state = 42)\nmodel3 = ensemble.RandomForestRegressor(n_estimators = 100, max_depth = 7, n_jobs = -1, random_state = 42)\n\n# Train the models on the training data.\nmodel1.fit(X1_balanced, y1_balanced)\nmodel2.fit(X2_balanced, y2_balanced)\nmodel3.fit(X3_balanced, y3_balanced)","metadata":{"papermill":{"duration":409.134256,"end_time":"2023-05-14T06:47:51.291301","exception":false,"start_time":"2023-05-14T06:41:02.157045","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-14T07:33:14.568624Z","iopub.execute_input":"2023-05-14T07:33:14.568967Z","iopub.status.idle":"2023-05-14T07:40:37.03773Z","shell.execute_reply.started":"2023-05-14T07:33:14.56894Z","shell.execute_reply":"2023-05-14T07:40:37.036819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Test Dataset","metadata":{"papermill":{"duration":0.036298,"end_time":"2023-05-14T06:47:51.363758","exception":false,"start_time":"2023-05-14T06:47:51.32746","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Set the directory path to the folder containing the CSV files.\ntdcsfog_test_path = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/tdcsfog'\n\n# Initialize an empty list to store the dataframes.\ntdcsfog_test_list = []\n\n# Loop through each file in the directory and read it into a dataframe.\nfor file_name in os.listdir(tdcsfog_test_path):\n    if file_name.endswith('.csv'):\n        file_path = os.path.join(tdcsfog_test_path, file_name)\n        file = pd.read_csv(file_path)\n        file['Id'] = file_name[:-4] + '_' + file['Time'].apply(str)\n        file.Time = file.Time \n        tdcsfog_test_list.append(file)","metadata":{"papermill":{"duration":0.1014,"end_time":"2023-05-14T06:47:51.501918","exception":false,"start_time":"2023-05-14T06:47:51.400518","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T15:45:38.180145Z","iopub.execute_input":"2023-05-25T15:45:38.180583Z","iopub.status.idle":"2023-05-25T15:45:38.198219Z","shell.execute_reply.started":"2023-05-25T15:45:38.180547Z","shell.execute_reply":"2023-05-25T15:45:38.197004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def slope(x): return (x[-1] - x[0]) / x[0] if x[0] else 0\ndef abs_diff_mean(x): return np.mean(np.abs(x[1:] - x[:-1])) if len(x) > 1 else 0\ndef diff_std(x): return np.std(x[1:] - x[:-1]) if len(x) > 1 else 0\n\nstrides = [5] # If stride size == window size there is no overlap between windows\nwindows = [10]\n\n\nfuncs = [make_robust(f) for f in [np.min,np.var, np.max, np.std, np.mean, slope, ss.skew, ss.kurtosis, abs_diff_mean, diff_std, np.sum,]]\n\nfc_test = FeatureCollection(\n    MultipleFeatureDescriptors(\n          functions=funcs,\n          series_names=[\"AccV\", \"AccML\", \"AccAP\"],\n          windows=windows,\n          strides=strides[0],\n    )\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T15:47:32.602329Z","iopub.execute_input":"2023-05-25T15:47:32.602822Z","iopub.status.idle":"2023-05-25T15:47:32.613755Z","shell.execute_reply.started":"2023-05-25T15:47:32.602776Z","shell.execute_reply":"2023-05-25T15:47:32.612732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tdcsfog_test = pd.DataFrame()\n\nfor idx, tdcsfog in enumerate(tdcsfog_test_list): \n    df_feats = fc_test.calculate(data=[tdcsfog], window_idx=\"end\", approve_sparsity=True, return_df=True)\n    df_feats = df_feats.join(tdcsfog)\n    tdcsfog_test = pd.concat([tdcsfog_test,df_feats],ignore_index = True)\n    \nprint(tdcsfog_test.tail())","metadata":{"execution":{"iopub.status.busy":"2023-05-25T15:49:42.849745Z","iopub.execute_input":"2023-05-25T15:49:42.850664Z","iopub.status.idle":"2023-05-25T15:49:43.643881Z","shell.execute_reply.started":"2023-05-25T15:49:42.850618Z","shell.execute_reply":"2023-05-25T15:49:43.641577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tdcsfog_test = reduce_memory_usage(tdcsfog_test)","metadata":{"papermill":{"duration":0.061227,"end_time":"2023-05-14T06:47:51.599527","exception":false,"start_time":"2023-05-14T06:47:51.5383","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T15:48:27.314356Z","iopub.execute_input":"2023-05-25T15:48:27.315136Z","iopub.status.idle":"2023-05-25T15:48:27.323899Z","shell.execute_reply.started":"2023-05-25T15:48:27.315089Z","shell.execute_reply":"2023-05-25T15:48:27.323002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the directory path to the folder containing the CSV files.\ndefog_test_path = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/defog'\n\n# Initialize an empty list to store the dataframes.\ndefog_test_list = []\n\n# Loop through each file in the directory and read it into a dataframe.\nfor file_name in os.listdir(defog_test_path):\n    if file_name.endswith('.csv'):\n        file_path = os.path.join(defog_test_path, file_name)\n        file = pd.read_csv(file_path)\n        file['Id'] = file_name[:-4] + '_' + file['Time'].apply(str)\n        file.Time = file.Time\n        defog_test_list.append(file)","metadata":{"papermill":{"duration":0.688802,"end_time":"2023-05-14T06:47:52.326278","exception":false,"start_time":"2023-05-14T06:47:51.637476","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T15:50:19.466906Z","iopub.execute_input":"2023-05-25T15:50:19.467401Z","iopub.status.idle":"2023-05-25T15:50:20.008841Z","shell.execute_reply.started":"2023-05-25T15:50:19.467362Z","shell.execute_reply":"2023-05-25T15:50:20.007941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"defog_test = pd.DataFrame()\n\nfor idx, defog in enumerate(defog_test_list): \n    df_feats = fc_test.calculate(data=[defog], window_idx=\"end\", approve_sparsity=True, return_df=True)\n    df_feats = df_feats.join(defog)\n    defog_test = pd.concat([defog_test,df_feats],ignore_index = True)\n    \nprint(defog_test.tail())","metadata":{"execution":{"iopub.status.busy":"2023-05-25T15:50:21.711231Z","iopub.execute_input":"2023-05-25T15:50:21.711678Z","iopub.status.idle":"2023-05-25T15:50:48.428990Z","shell.execute_reply.started":"2023-05-25T15:50:21.711644Z","shell.execute_reply":"2023-05-25T15:50:48.427530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"defog_test = reduce_memory_usage(defog_test)","metadata":{"papermill":{"duration":0.686019,"end_time":"2023-05-14T06:47:53.049474","exception":false,"start_time":"2023-05-14T06:47:52.363455","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T15:50:53.578477Z","iopub.execute_input":"2023-05-25T15:50:53.579486Z","iopub.status.idle":"2023-05-25T15:50:53.872202Z","shell.execute_reply.started":"2023-05-25T15:50:53.579417Z","shell.execute_reply":"2023-05-25T15:50:53.871252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.concat([tdcsfog_test, defog_test], axis = 0).reset_index(drop = True)\ntest = test.drop(columns=['Time'])\ntest","metadata":{"papermill":{"duration":0.234153,"end_time":"2023-05-14T06:47:53.320407","exception":false,"start_time":"2023-05-14T06:47:53.086254","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T15:54:11.572377Z","iopub.execute_input":"2023-05-25T15:54:11.572842Z","iopub.status.idle":"2023-05-25T15:54:11.676215Z","shell.execute_reply.started":"2023-05-25T15:54:11.572802Z","shell.execute_reply":"2023-05-25T15:54:11.674975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{"papermill":{"duration":0.037342,"end_time":"2023-05-14T06:47:53.395359","exception":false,"start_time":"2023-05-14T06:47:53.358017","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Separate the dataset for the independent variables.\n# Change by hand\ntest_X = test.iloc[:, 0:36]\n\n# Standardize the independent variables by a new scaler.\nscaler = StandardScaler()\ntest_X = scaler.fit_transform(test_X)\n\n# Get the predictions for the three models on the test data.\npred_y1 = model1.predict(test_X)\npred_y2 = model2.predict(test_X)\npred_y3 = model3.predict(test_X)\n\ntest['StartHesitation'] = pred_y1 # target variable for StartHesitation\ntest['Turn'] = pred_y2 # target variable for Turn\ntest['Walking'] = pred_y3 # target variable for Walking\n\ntest","metadata":{"papermill":{"duration":1.047587,"end_time":"2023-05-14T06:47:54.480581","exception":false,"start_time":"2023-05-14T06:47:53.432994","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-25T15:55:04.120187Z","iopub.execute_input":"2023-05-25T15:55:04.120639Z","iopub.status.idle":"2023-05-25T15:55:04.153153Z","shell.execute_reply.started":"2023-05-25T15:55:04.120606Z","shell.execute_reply":"2023-05-25T15:55:04.151248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{"papermill":{"duration":0.037147,"end_time":"2023-05-14T06:47:54.556874","exception":false,"start_time":"2023-05-14T06:47:54.519727","status":"completed"},"tags":[]}},{"cell_type":"code","source":"submission = test.iloc[:, 35:].fillna(0.0)\nsubmission","metadata":{"papermill":{"duration":0.220266,"end_time":"2023-05-14T06:47:54.817263","exception":false,"start_time":"2023-05-14T06:47:54.596997","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-14T07:40:39.662962Z","iopub.execute_input":"2023-05-14T07:40:39.663306Z","iopub.status.idle":"2023-05-14T07:40:39.789767Z","shell.execute_reply.started":"2023-05-14T07:40:39.663278Z","shell.execute_reply":"2023-05-14T07:40:39.788697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index = False)","metadata":{"papermill":{"duration":2.256699,"end_time":"2023-05-14T06:47:57.112488","exception":false,"start_time":"2023-05-14T06:47:54.855789","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-14T07:40:39.791585Z","iopub.execute_input":"2023-05-14T07:40:39.7924Z","iopub.status.idle":"2023-05-14T07:40:42.286661Z","shell.execute_reply.started":"2023-05-14T07:40:39.792362Z","shell.execute_reply":"2023-05-14T07:40:42.285704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save, Load, and Use Model\n\nTo save the trained Logistic Regression model, you can use the joblib library from the sklearn.externals module. This will save the model to a file in the current working directory. **To load the saved model later**, we can use the joblib.load() function.","metadata":{"papermill":{"duration":0.038824,"end_time":"2023-05-14T06:47:57.191566","exception":false,"start_time":"2023-05-14T06:47:57.152742","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import joblib\n\n# Save the model to disk.\njoblib.dump(model1, 'model1.joblib')\njoblib.dump(model2, 'model2.joblib')\njoblib.dump(model3, 'model3.joblib')\n\n# Load the saved models from disk.\nmodel1_loaded = joblib.load('model1.joblib')\nmodel2_loaded = joblib.load('model2.joblib')\nmodel3_loaded = joblib.load('model3.joblib')\n\n# Use the loaded models to make predictions on test data.\ny1_pred_loaded = model1_loaded.predict(test_X)\ny2_pred_loaded = model2_loaded.predict(test_X)\ny3_pred_loaded = model3_loaded.predict(test_X)","metadata":{"papermill":{"duration":1.274561,"end_time":"2023-05-14T06:47:58.505545","exception":false,"start_time":"2023-05-14T06:47:57.230984","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-14T07:40:42.289511Z","iopub.execute_input":"2023-05-14T07:40:42.290001Z","iopub.status.idle":"2023-05-14T07:40:43.569222Z","shell.execute_reply.started":"2023-05-14T07:40:42.289961Z","shell.execute_reply":"2023-05-14T07:40:43.567876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\n\nIt is possible that **more features or more advanced machine learning algorithms** could improve the accuracy of the models. Additionally, it may be useful to **investigate other factors** that contribute to the occurrence of freezing of gait events, such as cognitive or environmental factors.","metadata":{"papermill":{"duration":0.037949,"end_time":"2023-05-14T06:47:58.581718","exception":false,"start_time":"2023-05-14T06:47:58.543769","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"I am a medical doctor working on **artificial intelligence (AI) for medicine**. At present AI is also widely used in the medical field. Particularly, AI performs in the healthcare sector following tasks: **image classification, object detection, semantic segmentation, GANs, text classification, etc**. **If you are interested in AI for medicine, please see my other notebooks.**","metadata":{"papermill":{"duration":0.037761,"end_time":"2023-05-14T06:47:58.657688","exception":false,"start_time":"2023-05-14T06:47:58.619927","status":"completed"},"tags":[]}}]}